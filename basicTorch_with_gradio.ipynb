{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from torch.utils.data import dataset, DataLoader \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import gradio as gr \n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from torch.utils.data import dataset, DataLoader \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import gradio as gr \n",
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"CVD_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.loc[:, ~df.columns.isin([\"Heart_Disease\"])]\n",
    "targets = df.loc[:,df.columns.isin([\"Heart_Disease\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelBinarizer, LabelBinarizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, features, targets, transform=None):\n",
    "        self.raw_features = features \n",
    "        self.raw_targets = targets\n",
    "        \n",
    "        # Perform one-hot encoding on the features\n",
    "        self.column_transformer = ColumnTransformer([('one_hot_encoder', OneHotEncoder(sparse=False), \n",
    "                                                        self.raw_features.select_dtypes(include=['object']).columns)],\n",
    "                                                        remainder='passthrough')\n",
    "        self.new_features = self.column_transformer.fit_transform(self.raw_features)\n",
    "        self.label_binarizer = LabelBinarizer()\n",
    "        self.new_targets =  self.label_binarizer.fit_transform(self.raw_targets.iloc[:,0])\n",
    "        self.transform = transform \n",
    "        # self.dataloader = data_loader\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.raw_targets)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.new_features[index], self.new_targets[index]\n",
    "        if self.transform is not None:\n",
    "            sample = self.transform(sample)\n",
    "        return sample\n",
    "    \n",
    "    # def data_loader(self, batch_size=32, shuffle=True):\n",
    "    #     # Create a DataLoader for the current dataset instance\n",
    "    #     return DataLoader(dataset=self, batch_size=batch_size, shuffle=shuffle)\n",
    "    \n",
    "class to_tensor:\n",
    "    def __call__(self,sample):\n",
    "        features, targets= sample\n",
    "        return torch.tensor(features), torch.tensor(targets)\n",
    "    \n",
    "def transformInput(dataloader:\"dataloader\",df:\"dataframe\"):\n",
    "    return torch.tensor(dataloader.dataset.column_transformer.transform(df),dtype=torch.float64)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "dataset = MyDataset(features, targets, transform=to_tensor())\n",
    "dataloader = DataLoader(dataset, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# number of features (len of X cols)\n",
    "input_dim = 48\n",
    "# number of hidden layers\n",
    "hidden_layers = 25\n",
    "# number of classes (unique of y)\n",
    "output_dim = 2\n",
    "class Network(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Network, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_dim, hidden_layers)\n",
    "    self.linear2 = nn.Linear(hidden_layers, output_dim)\n",
    "  def forward(self, x):\n",
    "    x = torch.sigmoid(self.linear1(x))\n",
    "    x = self.linear2(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(clf.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "  running_loss = 0.0\n",
    "  for i, data in enumerate(dataloader, 0):\n",
    "    inputs, labels = data\n",
    "    # set optimizer to zero grad to remove previous epoch gradients\n",
    "    optimizer.zero_grad()\n",
    "    # forward propagation\n",
    "    outputs = clf(inputs)\n",
    "    prediction = torch.softmax(outputs,dim=1)\n",
    "    new_labels = torch.argmax(labels,dim=1)\n",
    "    loss = criterion(outputs, new_labels)\n",
    "    # backward propagation\n",
    "    loss.backward()\n",
    "    # optimize\n",
    "    optimizer.step()\n",
    "    running_loss += loss.item()\n",
    "  # display statistics\n",
    "  # print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 2000:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_1\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_2\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_3\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_4\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_5\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_6\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_7\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_8\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_9\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_10\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_11\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_12\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_13\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_14\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_15\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_16\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n",
      "/Users/tonderaimadamba/Library/Python/3.9/lib/python/site-packages/gradio/blocks.py:275: UserWarning: api_name predict already exists, using predict_17\n",
      "  warnings.warn(f\"api_name {api_name} already exists, using {api_name_}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def predict(\n",
    "            General_Health, Checkup, Exercise, Skin_Cancer, Other_Cancer,\n",
    "            Depression, Diabetes, Arthritis, Sex, Age_Category, Height_cm,Weight_kg, \n",
    "            BMI, Smoking_History,Alcohol_Consumption, Fruit_Consumption,\n",
    "            Green_Vegetables_Consumption, FriedPotato_Consumption):\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(\n",
    "        {\n",
    "            'General_Health' : [General_Health],\n",
    "            'Checkup' : [Checkup], \n",
    "            'Exercise' : [Exercise], \n",
    "            'Skin_Cancer' : [Skin_Cancer], \n",
    "            'Other_Cancer' : [Other_Cancer],\n",
    "            'Depression' : [Depression], \n",
    "            'Diabetes' : [Diabetes],\n",
    "            'Arthritis' : [Arthritis], \n",
    "            'Sex' : [Sex], \n",
    "            'Age_Category' : [Age_Category],\n",
    "            'Height_(cm)': [Height_cm], \n",
    "            'Weight_(kg)' : [Weight_kg], \n",
    "            'BMI' : [BMI], \n",
    "            'Smoking_History' : [Smoking_History],\n",
    "            'Alcohol_Consumption' : [Alcohol_Consumption], \n",
    "            'Fruit_Consumption' : [Fruit_Consumption],\n",
    "            'Green_Vegetables_Consumption' : [Green_Vegetables_Consumption], \n",
    "            'FriedPotato_Consumption' : [FriedPotato_Consumption]     \n",
    "        }\n",
    "    )\n",
    "    \n",
    "    data_df = transformInput(dataloader,df)\n",
    "    with torch.no_grad():\n",
    "        pred = clf(data_df)\n",
    "        probs = nn.functional.softmax(pred)\n",
    "        # pred_class = torch.argmax(probs, dim=1).tolist()\n",
    "        # pred_class = dataloader.dataset.label_binarizer.inverse_transform(probs)\n",
    "        #  tuple(predicted_class.tolist())\n",
    "        # pred_class = dataloader.dataset.label_binarizer.inverse_transform(pred_class)\n",
    "    # \n",
    "    return {\"No Heart Disease\": format(float(probs[0][0]), 'f'), \"Yes Heart Disease\": format(float(probs[0][1]), 'f')} \n",
    "\n",
    "\n",
    "demo = gr.Interface(\n",
    "    predict,\n",
    "    \n",
    "    \n",
    "    [\n",
    "        gr.Dropdown(['Poor', 'Very Good', 'Good', 'Fair', 'Excellent']),\n",
    "        gr.Dropdown(['Within the past 2 years', 'Within the past year','5 or more years ago','Within the past 5 years','Never']),\n",
    "        gr.Dropdown(['No', 'Yes']),\n",
    "        gr.Dropdown(['No', 'Yes']),\n",
    "        gr.Dropdown(['No', 'Yes']),\n",
    "        gr.Dropdown(['No', 'Yes']),\n",
    "        gr.Dropdown(['No','Yes','No, pre-diabetes or borderline diabetes','Yes, but female told only during pregnancy']),\n",
    "        gr.Dropdown(['Yes', 'No']),\n",
    "        gr.Dropdown(['Female', 'Male']),\n",
    "        gr.Dropdown(['70-74', '60-64', '75-79',   '80+', '65-69', '50-54', '45-49', '18-24','30-34', '55-59', '35-39', '40-44', '25-29']),\n",
    "        gr.Slider(60, 280),\n",
    "        gr.Slider(20, 300),\n",
    "        gr.Slider(10, 100),\n",
    "        gr.Dropdown(['No', 'Yes']),\n",
    "        gr.Slider(0, 30),\n",
    "        gr.Slider(0, 120),\n",
    "        gr.Slider(0, 130),\n",
    "        gr.Slider(0, 130),\n",
    "        ],\n",
    "    \"label\",\n",
    "    interpretation=\"default\",\n",
    "    live=True,\n",
    "    examples=[\n",
    "        ['Very Good','Within the past year','No','No','No','No','Yes','No','Female','70-74',165.0,77.11,28.29,'No',0.0,30.0,0.0,4.0],\n",
    "        ['Fair','5 or more years ago','Yes','Yes','Yes','No','Yes','No','Male','70-74',155.0,77.11,28.29,'No',0.0,30.0,0.0,4.0],\n",
    "    ],\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
